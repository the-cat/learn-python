{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why use Python for Data Analysis?\n",
    "What benefits does using Python give us over using Excel for data analysis?\n",
    "\n",
    "* Automated reproducible analysis\n",
    "* Working with large datasets\n",
    "* Analysis scripts as batch processes\n",
    "\n",
    "# The big four (five) of data analysis\n",
    "\n",
    "### load\n",
    "Reading data from different sources (databases, csv files, spreadsheets, APIs) and loading that in to an object we can work with.\n",
    "### manipulate\n",
    "Data cleaning and preparation to form a dataset that we can use to drive our analysis.\n",
    "### analyse\n",
    "Inspection of our data to answer a particular question.\n",
    "### visualise \n",
    "Reporting results in a clear way that conveys the findings of the analysis.\n",
    "### automate\n",
    "Reproducible analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python packages for Data Analysis\n",
    "\n",
    "For this introduction we will use the below Python modules. There are of course many more modules aimed at scientifc python and more advanced visualisations.\n",
    "\n",
    "* `numpy` - fundamental package for scientific computing with Python\n",
    "* `pandas` - powerful Python data analysis toolkit\n",
    "* `matplotlib` - 2D plotting library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Numpy and Pandas\n",
    "**The** library for Data Analysis in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "One-dimensional labelled array - a bit like a Python `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from 5 random numbers\n",
    "s_rand = pd.Series(np.random.rand(5))\n",
    "print(s_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from a python dictionary\n",
    "s_dict = pd.Series({'a': 34, 'b': 45, 'c': 56, 'd': 23, 'e':67})\n",
    "print(s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get items based on their label\n",
    "print(s_rand[3])\n",
    "print(s_dict['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "The labels that are assigned to our Series are an object called an **Index**. When working with *Series* and later *DataFrame*s it is important to understand the Index of your data. It is worth noting that this index doesn't have to be unique and it can contain multiple labels that create index levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set a custom index when creating a series\n",
    "s_rand = pd.Series(np.random.rand(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s_rand)\n",
    "print(s_rand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-dimensional labelled array, a bit like a database table, a spreadsheet or a `dict` or `Series`. Imagine each column in the table is represented as a `Series` and our `dict` labels these with a given column name - the result is a 2-dimensional dataset with labels for the **rows**(i.e the row index) **and the columns** (i.e the column index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'one': pd.Series(np.random.rand(3), index=['a', 'b', 'c']),\n",
    "     'two': pd.Series(np.random.rand(3), index=['a', 'b', 'c'])}\n",
    "\n",
    "pd.DataFrame(d)\n",
    "#print(df)\n",
    "#print(df.index)\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with DataFrames\n",
    "The `DataFrame` is a fundamental data structure for almost all data analysis using Pandas from loading data to visualisation. Let's start with the first of our big four - **loading data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "Loading data in Pandas is straightfoward. There is built-in support for loading data from flat files, Excel files, SQL tables, JSON etc...\n",
    "\n",
    "The functions for loading data have many options than can handle different forms of data within these formats.\n",
    "\n",
    "As a basic example, this repository includes a CSV file that contains some data about public transport journies in London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/tfl-journeys-type.csv')\n",
    "\n",
    "# Get the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the dataframe\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic stats about the DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Data\n",
    "Often we will want to select a subset of our data. There are lots of different ways to select data from a Series or DataFrame. The most commonly used are, `loc`, `iloc` and `[]`.\n",
    "#### `.loc`\n",
    "*Loc*ate data using the index, i.e **selecting data by label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently we just have an auto generated RangeIndex\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we can look up the row with the label 0, but can we re-label the rows in our DataFrame to be more useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DataFrame to have a new index\n",
    "df = df.set_index('Period and Financial year')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['01_10/11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also provide a list of labels\n",
    "df.loc[['01_10/11', '02_10/11']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.iloc`\n",
    "**I**nteger-**loc**ate, i.e **selecting data by position**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row using it's position - 0\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both loc and iloc are multi-dimensional\n",
    "df.iloc[0:5,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `[]` selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df[]` syntax is most often used for simple column selection. Selecting a column from a DataFrame returns a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tram Journeys (m)'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean indexing\n",
    "We can also select data based on some boolean conditions, similar to using `WHERE` in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following creates a boolean Series we can use to filter our DataFrame\n",
    "bus_filter = df['Bus journeys (m)'] > 200\n",
    "bus_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[bus_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(bus_filter) & (df['Underground journeys (m)'] > 115)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "This repository also includes a CSV file (`../data/Walking-Cycling.csv`) about the walking and cycling habits of residents of various London boroughs as well as averages for the country.\n",
    "\n",
    "1. Read the CSV file in to a DataFrame\n",
    "1. Inspect the DataFrame to get some basic information\n",
    "1. Set the index of the DataFrame to be a compound index from the columns `Local Authority` and `Year`.\n",
    "1. Using `iloc` implement an equivalent of the `head` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <-- your code here --> ##\n",
    "df = pd.read_csv('../data/Walking-Cycling.csv')\n",
    "print(df.shape)\n",
    "df['Frequency'].unique()\n",
    "df = df.set_index(['Year', 'Local Authority'])\n",
    "df = df[['Walking_%', 'Cycling_%']]\n",
    "df.iloc[0:5]\n",
    "cycling = df['Walking_%'] > 50\n",
    "df[cycling]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data\n",
    "\n",
    "The public transport dataset we have needs some cleaning and preparation before we do our analysis. `DataFrame` objects can be manipulated to deals with missing or dirty data.\n",
    "\n",
    "* working with missing data\n",
    "* handling data types\n",
    "* adding and removing columns\n",
    "\n",
    "We can remove column by selecting a subset of columns and reassigned the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/tfl-journeys-type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with missing data\n",
    "Some data relating to newer transport methods has missing data for the older reporting periods. This can be seen by calling `count` on our `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas handles these missing values pretty well and won't include these when performing any calculations such as `sum` or `mean`. However on occasion we might want to fill these missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emirates Airline Journeys (m)'] = df['Emirates Airline Journeys (m)'].fillna(value='dfg')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we might decide to remove the labels from our `DataFrame` where we have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling data types\n",
    "Often data that we read isn't imported in the right format and we have to do some work to clean up the data and get everything in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/tfl-journeys-type.csv')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Period beginning'] = pd.to_datetime(df['Period beginning'])\n",
    "df['Period ending'] = pd.to_datetime(df['Period ending'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding and removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Period and Financial year', 'Reporting Period', 'Bus journeys (m)', 'Underground journeys (m)']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can insert columns in a similar way to how we would add a new key to a Python `dict`. Here we are using the apply function to create a new column called 'Financial Year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Financial Year'] = df['Period and Financial year'].apply(lambda x:x[3:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this new column to create a sensible index for our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['Financial Year', 'Reporting Period'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Bus journeys (m)', 'Underground journeys (m)']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('14/15', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Analysis\n",
    "Once we have prepared our data, we can now begin the real analysis. Typically we are looking to answer some questions about the dataset we are working with. The answers to these questions will hopefully give us the information we need to make informed decisions based on this data.\n",
    "\n",
    "This repository also includes a CSV file called 'weather_data.csv'. This file contains some data about the weather in 3 different European cities. \n",
    "\n",
    "We can analyse this data to answer questions such as, \n",
    "\n",
    "* What is the maximum windspeed recorded in Rome? <br>\n",
    "* Which city has the highest average temperature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the weather data CSV\n",
    "df = pd.read_csv('../data/weather_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare different cities we need to group this dataset by the `city` column. You can visualise this grouping here\n",
    "![group](../img/group.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the city\n",
    "g = df.groupby(['city'])\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a DataFrameGroupBy object which we can then inspect to answer the questions we had about this data. The grouped object provides a mapping between group name and the group contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the groups in our group-by\n",
    "print(g.groups)\n",
    "\n",
    "# Print the contents if each group\n",
    "for name, group in g:\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the max windspeed in Rome\n",
    "print(g.get_group('Rome')['windspeed'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the city with maximum average windspeed\n",
    "g.mean()['windspeed'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Group our weather dataset by `date` to give 5 groups (one for each day). Use this grouping to find the day which was the coldest. (i.e minimum average temperate across the 3 cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## <-- your code here --> ##\n",
    "g = df.groupby(['date'])\n",
    "g\n",
    "# Get the groups in our group-by\n",
    "print(g.groups)\n",
    "\n",
    "# Print the contents if each group\n",
    "for name, group in g:\n",
    "    print(name)\n",
    "    print(group)\n",
    "    \n",
    "g.mean()['temperature'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Visualising data is important because often we want to present the findings of the analysis in a way that is easy to interpret. Data visualisation is itself a broad topic that explores how best to communicate information using various visualisation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Visualisation\n",
    "\n",
    "Many Pandas objects have some built-in plotting and visualisation functions to create some basic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a series of 5 random numbers\n",
    "s_rand = pd.Series(np.random.rand(5))\n",
    "s_rand.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of a random normal distribution\n",
    "s_normal_rand = pd.Series(np.random.normal(size=1000000))\n",
    "s_normal_rand.hist(buckets=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['city'])\n",
    "g.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customising Plots with Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the Walking-Cycling dataset. Extract the data relating to the 8 regions of England. Create a matplotlib figure that contains 4 subplots (one for each Walking-Cycling frequency). Plot a multi-line graph in each subplot that shows how the excerise habits of the people in these regions has changed over the period.\n",
    "\n",
    "Create a single legend for the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
